{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dificuldades, Decisões e Arquitetura\n",
    "A parte mais desafiadora de se desenvolver o coletor foi de tratar certas excessões que nem sempre são claras. Ao pensar na coleta é importante manter atenção à detalhes como repetição de links e páginas. Esses problemas não ocorrem em uma coleta ideal, mas as coisas não são perfeitas e os links podem entrar em loop. A parte complexa desses problemas é que eles não se manifestam como erro sintático e, portanto, é muito mais difícil identificar o local adequado para tratá-los. Vale lembrar que se o tratamento for feito de forma indevida podemos obter resultados inesperados na coleta.\n",
    "\n",
    "A principal decisão sobre esse coletor foi o de aproveitar ao máximo os recursos de dicionário para Python. Em outras linguagens poderia ser interessantes fazer uso de árvores, listas encadeadas, etc. para melhor lidar com os resultados. Porém, como a implementação de dicionários já está consolidada no Python, viu-se interessante usar ela para simplificar a abstração. Não só os dicionários foram um agente facilitador, mas as bibliotecas para tratamento de url e multithread também foram fundamentais para obter uma solução mais clara, abstraindo detalhes desnecessários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL's acessadas\n",
    "- PORTAL UOL. URL: https://www.uol.com.br. Último acesso em: 12/07/21.\n",
    "- PORTAL UAI. URL: https://www.uai.com.br. Último acesso em: 12/07/21.\n",
    "- PORTAL TERRA. URL: https://www.terra.com.br. Último acessso em: 12/07/21.\n",
    "- JORNAL BBC. URL: https://www.bbc.com. Último acesso em: 12/07/21.\n",
    "- PORTAL G1. URL: https://www.g1.globo.com. Último acesso em: 12/07/21.\n",
    "- PORTAL TECMUNDO. URL: https://www.tecmundo.com.br. Último acesso em:12/07/21.\n",
    "- PORTAL OLHARDIGITAL. URL: https://www.olhardigital.com.br. Último acesso em: 12/07/21.\n",
    "- PORTAL ESTADÃO. URL: https://www.estadao.com.br. Último acesso em: 12/07/21.\n",
    "- PORTAL ESTADO DE MINAS. URL: https://www.em.com.br. Último acesso em: 12/07/21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critérios e Protocolos\n",
    "O coletor precisa atender boas condutas para solicitar as páginas aos servidores. Para atender a essa política de boa navegação, pode-se elencar o método `get_next_url` da classe `Scheduler` no arquivo `scheduler.py`. Nele é possível encontrar o comando `sleep()` tendo como parâmetro uma constante de tempo que obedece aos protocolos de novas solicitações. Esse tipo de parada evita sobrecarregar o mesmo servidor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "TIME_LIMIT_BETWEEN_REQUESTS = 20\n",
    "# ...\n",
    "def get_next_url(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Obtém uma nova URL por meio da fila. Essa URL é removida da fila.\n",
    "        Logo após, caso o servidor não tenha mais URLs, o mesmo também é removido.\n",
    "        \"\"\"\n",
    "        for domain in self.dic_url_per_domain.keys():\n",
    "            if domain.is_accessible():\n",
    "                # Não extraia self.dic_url_per_domain[domain] para uma variável, pois essas modificações devem ser\n",
    "                # feitas por referência\n",
    "                if len(self.dic_url_per_domain[domain]) > 0:\n",
    "                    self.__acess_domain(domain)\n",
    "                    return self.dic_url_per_domain[domain].pop(0)\n",
    "        sleep(Scheduler.TIME_LIMIT_BETWEEN_REQUESTS)\n",
    "        return None, None\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando ainda na política de comportamento, podemos observar no método `request_url` da classe `PageFetcher` no arquivo `page_fetcher.py` que o User Agent é identificado por uma constante da classe e ela é uma string com o termo `Bot`. Isso permite a identificação correta do coletor ao fazer as solicitações aos servidores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "USER_AGENT = 'amarelaoBot'\n",
    "# ...\n",
    "def request_url(self, obj_url: ParseResult):\n",
    "        \"\"\"\n",
    "            Faz a requisição e retorna o conteúdo em binário da URL passada como parametro\n",
    "\n",
    "            obj_url: Instancia da classe ParseResult com a URL a ser requisitada.\n",
    "        \"\"\"\n",
    "        response = requests.get(url=obj_url.geturl(), headers={\n",
    "                                'User-Agent': PageFetcher.USER_AGENT})\n",
    "        return response.content if 'text/html' in response.headers['Content-Type'] else None\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# impacto na velocidade de coleta\n",
    "- quantidade de páginas por segundo\n",
    "- threads de 10 a 100\n",
    "- crescendo de 20 em 20 threads\n",
    "- coletanto sempre 100 páginas\n",
    "- recomendado usar: **seaborn**\n",
    "> gerar gráfico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
